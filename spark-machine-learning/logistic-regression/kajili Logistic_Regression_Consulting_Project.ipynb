{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Consulting Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Customer Churn\n",
    "\n",
    "A marketing agency has many customers that use their service to produce ads for the client/customer websites. They've noticed that they have quite a bit of churn in clients. They basically randomly assign account managers right now, but want you to create a machine learning model that will help predict which customers will churn (stop buying their service) so that they can correctly assign the customers most at risk to churn an account manager. Luckily they have some historical data, can you help them out? Create a classification algorithm that will help classify whether or not a customer churned. Then the company can test this against incoming data for future customers to predict which customers will churn and assign them an account manager.\n",
    "\n",
    "The data is saved as customer_churn.csv. Here are the fields and their definitions:\n",
    "\n",
    "    Name : Name of the latest contact at Company\n",
    "    Age: Customer Age\n",
    "    Total_Purchase: Total Ads Purchased\n",
    "    Account_Manager: Binary 0=No manager, 1= Account manager assigned\n",
    "    Years: Totaly Years as a customer\n",
    "    Num_sites: Number of websites that use the service.\n",
    "    Onboard_date: Date that the name of the latest contact was onboarded\n",
    "    Location: Client HQ Address\n",
    "    Company: Name of Client Company\n",
    "    \n",
    "Once you've created the model and evaluated it, test out the model on some new data (you can think of this almost like a hold-out set) that your client has provided, saved under new_customers.csv. The client wants to know which customers are most likely to churn given this data (they don't have the label yet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/kajili/spark-2.4.5-bin-hadoop2.7')\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('logreg-consult').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawData = spark.read.csv('customer_churn.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----+--------------+---------------+-----+---------+-------------------+--------------------+--------------------+-----+\n",
      "|           Names| Age|Total_Purchase|Account_Manager|Years|Num_Sites|       Onboard_date|            Location|             Company|Churn|\n",
      "+----------------+----+--------------+---------------+-----+---------+-------------------+--------------------+--------------------+-----+\n",
      "|Cameron Williams|42.0|       11066.8|              0| 7.22|      8.0|2013-08-30 07:00:40|10265 Elizabeth M...|          Harvey LLC|    1|\n",
      "|   Kevin Mueller|41.0|      11916.22|              0|  6.5|     11.0|2013-08-13 00:38:46|6157 Frank Garden...|          Wilson PLC|    1|\n",
      "|     Eric Lozano|38.0|      12884.75|              0| 6.67|     12.0|2016-06-29 06:20:07|1331 Keith Court ...|Miller, Johnson a...|    1|\n",
      "|   Phillip White|42.0|       8010.76|              0| 6.71|     10.0|2014-04-22 12:43:12|13120 Daniel Moun...|           Smith Inc|    1|\n",
      "|  Cynthia Norton|37.0|       9191.58|              0| 5.56|      9.0|2016-01-19 15:31:15|765 Tricia Row Ka...|          Love-Jones|    1|\n",
      "+----------------+----+--------------+---------------+-----+---------+-------------------+--------------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rawData.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Names='Cameron Williams', Age=42.0, Total_Purchase=11066.8, Account_Manager=0, Years=7.22, Num_Sites=8.0, Onboard_date=datetime.datetime(2013, 8, 30, 7, 0, 40), Location='10265 Elizabeth Mission Barkerburgh, AK 89518', Company='Harvey LLC', Churn=1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Names: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Total_Purchase: double (nullable = true)\n",
      " |-- Account_Manager: integer (nullable = true)\n",
      " |-- Years: double (nullable = true)\n",
      " |-- Num_Sites: double (nullable = true)\n",
      " |-- Onboard_date: timestamp (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Company: string (nullable = true)\n",
      " |-- Churn: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rawData.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Names',\n",
       " 'Age',\n",
       " 'Total_Purchase',\n",
       " 'Account_Manager',\n",
       " 'Years',\n",
       " 'Num_Sites',\n",
       " 'Onboard_date',\n",
       " 'Location',\n",
       " 'Company',\n",
       " 'Churn']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawData.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_cols = rawData.select(['Age',\n",
    "                                'Total_Purchase',\n",
    "                                'Account_Manager',\n",
    "                                'Years',\n",
    "                                'Num_Sites',\n",
    "                                'Churn'\n",
    "                                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+---------------+-----+---------+-----+\n",
      "| Age|Total_Purchase|Account_Manager|Years|Num_Sites|Churn|\n",
      "+----+--------------+---------------+-----+---------+-----+\n",
      "|42.0|       11066.8|              0| 7.22|      8.0|    1|\n",
      "|41.0|      11916.22|              0|  6.5|     11.0|    1|\n",
      "|38.0|      12884.75|              0| 6.67|     12.0|    1|\n",
      "|42.0|       8010.76|              0| 6.71|     10.0|    1|\n",
      "|37.0|       9191.58|              0| 5.56|      9.0|    1|\n",
      "+----+--------------+---------------+-----+---------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "relevant_cols.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = relevant_cols.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import (VectorAssembler,VectorIndexer,\n",
    "                                OneHotEncoderEstimator,StringIndexer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location_indexer = StringIndexer(inputCol='Location',outputCol='LocationIndex')\n",
    "# location_encoder = OneHotEncoderEstimator(inputCols=['LocationIndex'],outputCols=['LocationVec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# company_indexer = StringIndexer(inputCol='Company',outputCol='CompanyIndex')\n",
    "# company_encoder = OneHotEncoderEstimator(inputCols=['CompanyIndex'],outputCols=['CompanyVec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Age', 'Total_Purchase', 'Account_Manager', 'Years', 'Num_Sites', 'Churn']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=['Age', 'Total_Purchase', 'Account_Manager', 'Years', 'Num_Sites'],\n",
    "                            outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_customer_obj = LogisticRegression(featuresCol='features', labelCol='Churn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[assembler,log_reg_customer_obj])\n",
    "                            #location_indexer,company_indexer,\n",
    "                            #location_encoder,company_encoder,\n",
    "                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = final_data.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_churn_model = pipeline.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customer_churn_model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = customer_churn_model.transform(test_data)\n",
    "type(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "|Churn|prediction|\n",
      "+-----+----------+\n",
      "|    0|       0.0|\n",
      "|    1|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    1|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    1|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    1|       0.0|\n",
      "|    1|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    1|       1.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    1|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    1|       1.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    1|       1.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    1|       1.0|\n",
      "|    0|       0.0|\n",
      "|    0|       1.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    1|       0.0|\n",
      "|    0|       1.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       1.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    1|       1.0|\n",
      "|    1|       0.0|\n",
      "|    1|       1.0|\n",
      "|    1|       1.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    1|       0.0|\n",
      "|    1|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "+-----+----------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results.select('Churn', 'prediction').show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-------------------+\n",
      "|summary|              Churn|         prediction|\n",
      "+-------+-------------------+-------------------+\n",
      "|  count|                285|                285|\n",
      "|   mean|0.17543859649122806|0.15087719298245614|\n",
      "| stddev| 0.3810108412907983| 0.3585587381003972|\n",
      "|    min|                  0|                0.0|\n",
      "|    max|                  1|                1.0|\n",
      "+-------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results.select('Churn', 'prediction').describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+---------------+-----+---------+-----+--------------------+--------------------+--------------------+----------+\n",
      "| Age|Total_Purchase|Account_Manager|Years|Num_Sites|Churn|            features|       rawPrediction|         probability|prediction|\n",
      "+----+--------------+---------------+-----+---------+-----+--------------------+--------------------+--------------------+----------+\n",
      "|28.0|      11245.38|              0| 6.72|      8.0|    0|[28.0,11245.38,0....|[4.61300168030154...|[0.99017548780141...|       0.0|\n",
      "|29.0|       8688.17|              1|  5.7|      9.0|    1|[29.0,8688.17,1.0...|[3.08220266060859...|[0.95615262351480...|       0.0|\n",
      "|29.0|       9617.59|              0| 5.49|      8.0|    0|[29.0,9617.59,0.0...|[5.05827861987195...|[0.99368365773952...|       0.0|\n",
      "|29.0|      11274.46|              1| 4.43|      8.0|    0|[29.0,11274.46,1....|[4.93997730897524...|[0.99289606622698...|       0.0|\n",
      "|29.0|      12711.15|              0| 5.74|      7.0|    0|[29.0,12711.15,0....|[6.23389639946536...|[0.99804204804059...|       0.0|\n",
      "|30.0|       8874.83|              0| 5.56|      9.0|    0|[30.0,8874.83,0.0...|[3.65754002625491...|[0.97485280243563...|       0.0|\n",
      "|30.0|      10744.14|              1| 7.16|      9.0|    1|[30.0,10744.14,1....|[2.34054337523319...|[0.91217962360114...|       0.0|\n",
      "|30.0|      10960.52|              1| 5.96|      9.0|    0|[30.0,10960.52,1....|[2.88358333666904...|[0.94702891045128...|       0.0|\n",
      "|30.0|      12788.37|              0| 4.31|     10.0|    0|[30.0,12788.37,0....|[2.98420268391555...|[0.95185533281065...|       0.0|\n",
      "|31.0|       8829.83|              1| 4.52|      8.0|    0|[31.0,8829.83,1.0...|[4.68583134807848...|[0.99085926169357...|       0.0|\n",
      "|31.0|      10058.87|              1| 6.54|      7.0|    0|[31.0,10058.87,1....|[5.04920406704807...|[0.99362644588388...|       0.0|\n",
      "|31.0|      11297.57|              1| 6.23|     10.0|    1|[31.0,11297.57,1....|[1.40046951160218...|[0.80225838238858...|       0.0|\n",
      "|32.0|       6367.22|              1| 2.84|     10.0|    0|[32.0,6367.22,1.0...|[2.79631425923993...|[0.94247632834987...|       0.0|\n",
      "|32.0|       7896.65|              0| 7.12|      8.0|    0|[32.0,7896.65,0.0...|[4.01666743191262...|[0.98230582900911...|       0.0|\n",
      "|32.0|       8011.38|              0| 5.35|     10.0|    0|[32.0,8011.38,0.0...|[2.28440233290437...|[0.90757698215864...|       0.0|\n",
      "|32.0|       8617.98|              1|  6.2|     10.0|    1|[32.0,8617.98,1.0...|[1.29661873941922...|[0.78526537244771...|       0.0|\n",
      "|32.0|       9885.12|              1| 6.92|      9.0|    1|[32.0,9885.12,1.0...|[2.24685421630724...|[0.90437884063837...|       0.0|\n",
      "|32.0|      11540.86|              0|  3.0|      7.0|    0|[32.0,11540.86,0....|[7.16812627337060...|[0.99922982803899...|       0.0|\n",
      "|32.0|      11715.72|              0| 4.73|      9.0|    0|[32.0,11715.72,0....|[3.85703171095901...|[0.97930663545590...|       0.0|\n",
      "|32.0|       12403.6|              0| 4.99|      7.0|    0|[32.0,12403.6,0.0...|[6.27648665126870...|[0.99812353366595...|       0.0|\n",
      "+----+--------------+---------------+-----+---------+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_eval_obj = BinaryClassificationEvaluator(rawPredictionCol='prediction',\n",
    "                                            labelCol='Churn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "AreaUnderCurve = my_eval_obj.evaluate(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7965957446808511"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AreaUnderCurve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
